# 审核步骤

**重要提示：这是自动化流程（计划 → 执行 → 审核 → 修复）4步中的第3步。**
- **没有人工介入** - 您的输出将直接输入到"修复"步骤
- **不要**询问类似"您需要我修复这个吗？"的问题
- **不要**主动提出进行修改 - 只需记录发现的问题
- "修复"步骤将自动处理您报告的所有内容
- 直接、客观地陈述 - 无需对话式语言

对照.task计划审查实施情况。

## 1. 首先验证结果（最重要！）
阅读.task文件中的EXPECTED_OUTCOME和OUTCOME_VERIFICATION。
**实际运行验证步骤**以确认结果已达成：
- 如果写着"按钮存在且href=/login" → 使用grep/search查找它
- 如果写着"API返回200" → 使用curl调用该端点
- 如果写着"显示错误消息" → 检查组件是否渲染了它
- 如果写着"在X位置创建文件" → 验证文件是否存在

**如果结果未达成**：这是🔴 **阻塞问题** - 任务未完成。
**如果结果已达成**：继续代码质量检查。

## 2. 检查计划合规性
- EXISTING_CODE是否被复用？
- PATTERNS是否被遵循？
- 所有PLAN步骤都完成了吗？

## 自动检测重点区域
根据实现内容，检查相关领域：

**如果涉及认证/密码/令牌/API密钥：**
- 输入验证和清理
- 没有硬编码的密钥
- 安全的令牌处理

**如果涉及数据库/SQL：**
- 预处理语句（防止SQL注入）
- 正确的错误处理

**如果涉及用户输入/表单：**
- 输入验证
- XSS防护（转义输出）

**如果涉及API端点：**
- 正确的响应格式
- 错误响应
- 认证检查

**如果涉及异步/状态：**
- 竞态条件检查
- 错误状态处理

**如果涉及UI：**
- 是否符合设计系统（如果存在specs/DESIGN_SYSTEM.md）
- 基础可访问性

## 运行检查
使用.task文件中的TEST_COMMAND（或根据CONTEXT.md检测）

## 测试方法
检查项目中存在的测试基础设施：
- 如果测试存在 → 运行它们，确保新代码被覆盖
- 测试期望取决于上下文（如果存在模式特定指导，请参考）

## 按类型和严重性分类问题

### 问题类型：
- 🔧 **环境问题**：缺少工具、依赖、容器设置错误、需要配置
- 💻 **代码问题**：错误、逻辑错误、安全问题、缺少错误处理

### 严重性：
- 🔴 **阻塞问题**：安全漏洞、数据丢失风险、崩溃
- 🟡 **问题**：错误、逻辑错误、缺少错误处理
- 🟢 **建议**：样式改进、小优化

## 关键点：环境问题是可解决的，不是阻塞问题
如果遇到环境问题（缺少工具、依赖、设置错误）：
- 这**不是**阻塞问题 - 而是**可解决的问题**
- 示例："未安装Chrome"、"缺少npm包"、"Docker需要配置"
- 标记为：🔧 **环境问题**（不是阻塞问题）
- 包含**修复方案**：需要安装/配置什么来修复它

## 关键点：必须标记预先存在的问题
如果发现构建损坏、测试失败或其他问题：
- 即使它们在当前任务之前**已存在**，也要标记它们
- **不要**以"预先存在，不阻塞"为由忽略问题
- 损坏的代码库就是损坏的代码库 - 必须修复
- "修复"步骤将处理所有标记的问题
- 如果某些操作失败（db:push、测试、构建），将其标记为**问题**

## 对照待处理任务检查
在标记未使用代码之前，检查TASKS.md：
- 是否有待处理任务会用到它？ → 不是问题，备注"为任务X搭建脚手架"
- 没有待处理任务需要它？ → 标记为**问题**：移除死代码

不要因为脚手架而抑制警告。不要保留实际的死代码。

## 附加到.task：
```
REVIEW_RESULT:
OUTCOME_ACHIEVED: 是/否
OUTCOME_EVIDENCE: [您检查的内容和发现]
BUILD_PASSED: 是/否
TESTS_PASSED: 是/否

ENVIRONMENT_ISSUES:
- [类型] [描述] → 修复方案：[如何修复]

BLOCKERS:
- [如果有 - 包括结果未达成的情况]

ISSUES:
- [如果有]

SUGGESTIONS:
- [如果有，简要说明]
```

如果一切正常，写入：
```
REVIEW_RESULT:
OUTCOME_ACHIEVED: 是
OUTCOME_EVIDENCE: [简要证明]
BUILD_PASSED: 是
TESTS_PASSED: 是
ISSUES: 无
```